{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p300 model by Deepchem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMsIRgYP/CFmgiO1uIxFfS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohmadyudiutomo/p300/blob/main/p300_model_by_Deepchem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAzahKF0-puA"
      },
      "source": [
        "#DEEPCHEM for preparing p300 activity prediction\n",
        "must run in GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg34tLtB-o6F",
        "outputId": "a4156d83-7572-4029-c02e-c1443b16ee3a"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ad/769c195c72ac72040635c66cd9ba7b0f4b4fc1ac67e59b99fa6988446c22/tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorflow-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZvgLJBK-9lL",
        "outputId": "9b5591e5-3897-46e6-ede9-7eb775d4b733"
      },
      "source": [
        "# Installing conda\n",
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3490  100  3490    0     0  16859      0 --:--:-- --:--:-- --:--:-- 16859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
            "python version: 3.6.9\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit, openmm, pdbfixer\n",
            "added omnia to channels\n",
            "added conda-forge to channels\n",
            "done\n",
            "conda packages installation finished!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "WF-u7INB_4jP",
        "outputId": "f9a0a5e2-3648-4bef-b15c-d70a91df5e6f"
      },
      "source": [
        "# Installing Deepchem\n",
        "!pip install --pre deepchem\n",
        "import deepchem\n",
        "deepchem.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepchem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/5c/ab3d2efc10f29b71e2b09d0ddc62a767c5f2ab0007914e673b8ff2c2a905/deepchem-2.4.0rc1.dev20201116174536.tar.gz (401kB)\n",
            "\r\u001b[K     |▉                               | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 14.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40kB 12.3MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 92kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 102kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 122kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 133kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 143kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 153kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 163kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 174kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 184kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 194kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 204kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 215kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 225kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 235kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 245kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 256kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 266kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 276kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 286kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 296kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 307kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 317kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 327kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 337kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 348kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 358kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 368kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 378kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 389kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 399kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from deepchem) (0.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Building wheels for collected packages: deepchem\n",
            "  Building wheel for deepchem (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepchem: filename=deepchem-2.4.0rc1.dev20201118013711-cp36-none-any.whl size=516159 sha256=1c5995bb1c8045f89688d5aa0d98b163a483b8413bb4b32ba6d65a7b8ddd4c50\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/62/46/62d0ff22abaf0778aa1ef94cde4282cb45fcb190f5cdd4ec75\n",
            "Successfully built deepchem\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.4.0rc1.dev20201118013711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0-rc1.dev'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxhIODSt_4_X",
        "outputId": "cfbdde95-a15e-4af8-ae48-a936fc083534"
      },
      "source": [
        "# Getting the dataset\n",
        "!wget https://raw.githubusercontent.com/rohmadyudiutomo/p300/main/Cur%20der%20p300%20from%20Yang%20et%20al%20mix%20cur%20filter.csv\n",
        "from deepchem.utils.save import load_from_disk\n",
        "dataset_file= \"Cur der p300 from Yang et al mix cur filter.csv\"\n",
        "\n",
        "# Loading the data from the CSV file\n",
        "loader = deepchem.data.CSVLoader(tasks=[\"pIC50\"], \n",
        "                                 smiles_field=\"SMILES\", \n",
        "                                 featurizer=deepchem.feat.ConvMolFeaturizer())\n",
        "# Featurizing the dataset with ConvMolFeaturizer\n",
        "dataset = loader.featurize(dataset_file)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-18 03:18:09--  https://raw.githubusercontent.com/rohmadyudiutomo/p300/main/Cur%20der%20p300%20from%20Yang%20et%20al%20mix%20cur%20filter.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13978 (14K) [text/plain]\n",
            "Saving to: ‘Cur der p300 from Yang et al mix cur filter.csv.1’\n",
            "\n",
            "Cur der p300 from Y 100%[===================>]  13.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-18 03:18:10 (105 MB/s) - ‘Cur der p300 from Yang et al mix cur filter.csv.1’ saved [13978/13978]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "smiles_field is deprecated and will be removed in a future version of DeepChem.Use feature_field instead.\n",
            "/usr/local/lib/python3.6/dist-packages/deepchem/data/data_loader.py:162: FutureWarning: featurize() is deprecated and has been renamed to create_dataset().featurize() will be removed in DeepChem 3.0\n",
            "  \"featurize() will be removed in DeepChem 3.0\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI-HAwLx_-w-"
      },
      "source": [
        "# Splitter splits the dataset \n",
        "# In this case it's is an equivalent of train_test_split from sklearn\n",
        "splitter = deepchem.splits.RandomSplitter()\n",
        "# frac_test is 0.01 because we only use a train and valid as an example\n",
        "train, valid, _ = splitter.train_valid_test_split(dataset,\n",
        "                                                  frac_train=0.7,\n",
        "                                                  frac_valid=0.29,\n",
        "                                                  frac_test=0.01)\n",
        "# Normalizer will normalize y values in the dataset\n",
        "normalizer = deepchem.trans.NormalizationTransformer(transform_y=True, \n",
        "                                                     dataset=train, \n",
        "                                                     move_mean=True)\n",
        "train = normalizer.transform(train)\n",
        "test = normalizer.transform(valid)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV5KS-KzACDz",
        "outputId": "dc0909d2-05c2-4d37-aae7-990c464abf1a"
      },
      "source": [
        "print(f\"Size of the training data: {len(train.ids)}\")\n",
        "print(f\"Size of the validation data: {len(valid.ids)}\")\n",
        "print(test)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the training data: 102\n",
            "Size of the validation data: 43\n",
            "<DiskDataset X.shape: (43,), y.shape: (43, 1), w.shape: (43, 1), ids: ['CC1=NN(c2ccc(C(=O)O)cc2)C(=O)/C1=C\\\\c1ccc(-c2cc(C)c(C)cc2[N+](=O)[O-])o1'\n",
            " 'O=C1/C(=C/c2ccc(O)c(Br)c2)CCC/C1=C\\\\c1ccc(O)c(Br)c1'\n",
            " 'CC(C)N(Cc1ccc2c(c1)C=CC(C)(C)O2)S(=O)(=O)c1ccccn1' ...\n",
            " 'O=C(c1ccc(O)c(NC(=O)c2cccc3ccccc23)c1)c1ccc(O)c(NC(=O)c2cccc3ccccc23)c1'\n",
            " 'CNC(=O)Nc1ccc2c(c1)CC[C@@]21OC(=O)N(CC(=O)N(Cc2ccccc2)[C@H](C)C2CC2)C1=O'\n",
            " 'C[C@H](C1CC1)N(Cc1ccccc1)C(=O)CN1C(=O)N[C@@]2(CCc3ccccc32)C1=O'], task_names: ['pIC50']>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkYt-oDCAavr"
      },
      "source": [
        "# GraphConvModel is a GNN model based on \n",
        "# Duvenaud, David K., et al. \"Convolutional networks on graphs for\n",
        "# learning molecular fingerprints.\"\n",
        "from deepchem.models import GraphConvModel\n",
        "graph_conv = GraphConvModel(1,\n",
        "                            batch_size=30,\n",
        "                            mode=\"regression\")\n",
        "# Defining metric. Closer to 1 is better\n",
        "metric = deepchem.metrics.Metric(deepchem.metrics.pearson_r2_score)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKd-yDFJAdZA",
        "outputId": "d384f1c4-1eeb-46e4-adac-b4cbe554a0ef"
      },
      "source": [
        "# Fitting the model\n",
        "graph_conv.fit(train, nb_epoch=100)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03761035919189453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir5mUYGPAgOB",
        "outputId": "304c1267-f570-41e6-9167-ff33b8e158a2"
      },
      "source": [
        "# Reversing the transformation and getting the metric scores on 2 datasets\n",
        "train_scores = graph_conv.evaluate(train, [metric], [normalizer])\n",
        "valid_scores = graph_conv.evaluate(valid, [metric], [normalizer])\n",
        "test_scores = graph_conv.evaluate(test, [metric], [normalizer])\n",
        "print(f\"Train Scores: {train_scores}\")\n",
        "print(f\"Validation Scores: {valid_scores}\")\n",
        "print(f\"test Scores: {test_scores}\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Scores: {'pearson_r2_score': 0.9602700641681027}\n",
            "Validation Scores: {'pearson_r2_score': 0.4485035953563968}\n",
            "test Scores: {'pearson_r2_score': 0.4485036017635912}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozCSGVWsAo5N"
      },
      "source": [
        "smiles = ['O=C(CC(/C=C/C1=CC=C(O)C(O)=C1)=O)/C=C/C2=CC(OC)=C(O)C=C2','O=C(CC(/C=C/C1=CC=C(O)C(O)=C1)=O)/C=C/C2=CC(OC(O)=O)=C(O)C=C2','O=C(CC(/C=C/C1=CC=C(O)C(O)=C1)=O)/C=C/C2=CC(Br)=C(O)C=C2','O=C(CC(/C=C/C1=CC=C(O)C(OC)=C1)=O)/C=C/C2=CC(OC(O)=O)=C(O)C=C2','O=C(CC(/C=C/C1=CC=C(O)C(OC)=C1)=O)/C=C/C2=CC(Br)=C(O)C=C2','O=C(CC(/C=C/C1=CC=C(O)C(Br)=C1)=O)/C=C/C2=CC(OC(O)=O)=C(O)C=C2','O=C(/C(CCC/1)=C/C2=CC(OC)=C(O)C=C2)C1=C\\C3=CC=C(O)C(O)=C3','O=C(/C(CCC/1)=C/C2=CC(OC(O)=O)=C(O)C=C2)C1=C\\C3=CC=C(O)C(O)=C3','O=C(/C(CCC/1)=C/C2=CC(Br)=C(O)C=C2)C1=C\\C3=CC=C(O)C(O)=C3','O=C(/C(CCC/1)=C/C2=CC(OC(O)=O)=C(O)C=C2)C1=C\\C3=CC=C(O)C(OC)=C3','O=C(/C(CCC/1)=C/C2=CC(Br)=C(O)C=C2)C1=C\\C3=CC=C(O)C(OC)=C3','O=C(/C(CCC/1)=C/C2=CC(OC(O)=O)=C(O)C=C2)C1=C\\C3=CC=C(O)C(Br)=C3','O=C(CC(/C=C/C1=CC=C(O)C(OC)=C1)=O)/C=C/C2=CC(OC)=C(O)C=C2','O=C1/C(CCC/C1=C\\C2=CC=C(C(Br)=C2)O)=C/C3=CC(Br)=C(C=C3)O']"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXoAkfdCAtUu",
        "outputId": "ac425eaf-124d-47fd-c8de-d62c0864db23"
      },
      "source": [
        "from rdkit import Chem\n",
        "mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
        "featurizer = deepchem.feat.ConvMolFeaturizer()\n",
        "x = featurizer.featurize(mols)\n",
        "\n",
        "predicted_pIC50 = graph_conv.predict_on_batch(x)\n",
        "predicted_pIC50"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.20332716],\n",
              "       [-0.29523158],\n",
              "       [ 0.27267447],\n",
              "       [-0.17727722],\n",
              "       [ 0.3948581 ],\n",
              "       [ 0.5273888 ],\n",
              "       [-1.5807843 ],\n",
              "       [-1.1606088 ],\n",
              "       [-0.6668961 ],\n",
              "       [-1.1699895 ],\n",
              "       [-0.47290358],\n",
              "       [-0.3007403 ],\n",
              "       [-0.28920236],\n",
              "       [ 0.2197175 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    }
  ]
}